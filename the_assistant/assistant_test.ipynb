{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c8570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imaplib\n",
    "\n",
    "# Account credentials\n",
    "imap_host = 'imap.mail.yahoo.com'\n",
    "\n",
    "# Connect to the server using SSL\n",
    "imap = imaplib.IMAP4_SSL(imap_host)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596ff24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imaplib\n",
    "\n",
    "username = 'jixaw31@yahoo.com'\n",
    "password = \"awykmzudzbrbuhoq\"  # your app password\n",
    "\n",
    "imap_server = 'imap.mail.yahoo.com'\n",
    "imap_port = 993\n",
    "\n",
    "try:\n",
    "    imap = imaplib.IMAP4_SSL(imap_server, imap_port)\n",
    "    status, response = imap.login(username, password)\n",
    "    if status == 'OK':\n",
    "        print(\"OK\")\n",
    "except imaplib.IMAP4.error:\n",
    "    print(\"Generate app password\")\n",
    "\n",
    "# Select the mailbox you want to use (INBOX)\n",
    "imap.select('INBOX')\n",
    "\n",
    "# Search for all emails in the mailbox\n",
    "status, messages = imap.search(None, 'ALL')\n",
    "\n",
    "# Convert messages to a list of email IDs\n",
    "email_ids = messages[0].split()\n",
    "\n",
    "len(email_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c93f964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the email by ID\n",
    "status, msg_data = imap.fetch(email_ids[-5], '(RFC822)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96a4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject (Title): You have an invitation\n",
      "Content (Body): Mohammad Sadegh, Machine Learning Engineer from Shahid Bahonar University of Kerman is waiting for your response\n",
      "        \n",
      "Hi M.Ali, I’d like to join your professional network\n",
      "\n",
      "Mohammad Sadegh Seyfi\n",
      "Computer Engineering Student | Data Enthusiastic  | Machine Learning Enthusiastic | Classic Full-Stack PHP Developer\n",
      "Kerman Province, Iran\n",
      "5 connections in common\n",
      "See all connections in common:https://www.linkedin.com/comm/search/results/people/?facetNetwork=%5B%22F%22%5D&facetConnectionOf=%5B%22ADoAADBem60BAb66xTJvYyq6elkmsdhCC1a0-UI%22%5D&origin=SHARED_CONNECTIONS_CANNED_SEARCH&lipi=urn%3Ali%3Apage%3Aemail_email_m2m_invite_single_01%3Bmg310yLtQeCTh1ac%2FetW1Q%3D%3D&midToken=AQGV55UYyLjfaw&midSig=0tZWhdVUzIhHM1&trk=eml-email_m2m_invite_single_01-connections~in~common~text-0-view~connections&trkEmail=eml-email_m2m_invite_single_01-connections~in~common~text-0-view~connections-null-6b6odl~majnvnu4~2u-null-null&eid=6b6odl-majnvnu4-2u&otpToken=MTEwZDFmZTUxYTJhY2FjMmI1MjQwNGVkNDIxOGVlYjI4N2NhZDQ0Mjk4YWU4NjYxNzBjNjA4NmQ0YTViNWFmMmYwZDNkZjg0MWFjN2JlZmU1YTkwZDBhMWFjNjExM2U1OTYxZDAwNDY1NGM2YTA1Zjc5M2IzYiwxLDE%3D\n",
      "\n",
      "Accept:https://www.linkedin.com/comm/mynetwork/invite-accept/invitationId/7327312303379378176/sharedKey/UP6NAzw5/?inviterVanityName=mohammad-sadegh-seyfi-a659311a7&lipi=urn%3Ali%3Apage%3Aemail_email_m2m_invite_single_01%3Bmg310yLtQeCTh1ac%2FetW1Q%3D%3D&midToken=AQGV55UYyLjfaw&midSig=0tZWhdVUzIhHM1&trk=eml-email_m2m_invite_single_01-null-0-null&trkEmail=eml-email_m2m_invite_single_01-null-0-null-null-6b6odl~majnvnu4~2u-null-null&eid=6b6odl-majnvnu4-2u&otpToken=MTEwZDFmZTUxYTJhY2FjMmI1MjQwNGVkNDIxOGVlYjI4N2NhZDQ0Mjk4YWU4NjYxNzBjNjA4NmQ0YTViNWFmMmYwZDNkZjg0MWFjN2JlZmU1YTkwZDBhMWFjNjExM2U1OTYxZDAwNDY1NGM2YTA1Zjc5M2IzYiwxLDE%3D\n",
      "View profile:https://ir.linkedin.com/comm/in/mohammad-sadegh-seyfi-a659311a7?lipi=urn%3Ali%3Apage%3Aemail_email_m2m_invite_single_01%3Bmg310yLtQeCTh1ac%2FetW1Q%3D%3D&midToken=AQGV55UYyLjfaw&midSig=0tZWhdVUzIhHM1&trk=eml-email_m2m_invite_single_01-null-0-null&trkEmail=eml-email_m2m_invite_single_01-null-0-null-null-6b6odl~majnvnu4~2u-null-null&eid=6b6odl-majnvnu4-2u&otpToken=MTEwZDFmZTUxYTJhY2FjMmI1MjQwNGVkNDIxOGVlYjI4N2NhZDQ0Mjk4YWU4NjYxNzBjNjA4NmQ0YTViNWFmMmYwZDNkZjg0MWFjN2JlZmU1YTkwZDBhMWFjNjExM2U1OTYxZDAwNDY1NGM2YTA1Zjc5M2IzYiwxLDE%3D\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "This email was intended for M.Ali Irandoost (Python | AI | Pytorch | TensorFlow | Scikit-learn | Computer Vision | OpenCV | NLP | Time Series | FastAPI | LangChain | LangGraph | CrewAI | Numpy | Pandas | PostgreSQL)\n",
      "Learn why we included this: https://www.linkedin.com/help/linkedin/answer/4788?lang=en&lipi=urn%3Ali%3Apage%3Aemail_email_m2m_invite_single_01%3Bmg310yLtQeCTh1ac%2FetW1Q%3D%3D&midToken=AQGV55UYyLjfaw&midSig=0tZWhdVUzIhHM1&trk=eml-email_m2m_invite_single_01-SecurityHelp-0-textfooterglimmer&trkEmail=eml-email_m2m_invite_single_01-SecurityHelp-0-textfooterglimmer-null-6b6odl~majnvnu4~2u-null-null&eid=6b6odl-majnvnu4-2u&otpToken=MTEwZDFmZTUxYTJhY2FjMmI1MjQwNGVkNDIxOGVlYjI4N2NhZDQ0Mjk4YWU4NjYxNzBjNjA4NmQ0YTViNWFmMmYwZDNkZjg0MWFjN2JlZmU1YTkwZDBhMWFjNjExM2U1OTYxZDAwNDY1NGM2YTA1Zjc5M2IzYiwxLDE%3D\n",
      "You are receiving LinkedIn invitations emails.\n",
      "\n",
      "Unsubscribe: https://www.linkedin.com/comm/psettings/email-unsubscribe?lipi=urn%3Ali%3Apage%3Aemail_email_m2m_invite_single_01%3Bmg310yLtQeCTh1ac%2FetW1Q%3D%3D&midToken=AQGV55UYyLjfaw&midSig=0tZWhdVUzIhHM1&trk=eml-email_m2m_invite_single_01-unsubscribe-0-textfooterglimmer&trkEmail=eml-email_m2m_invite_single_01-unsubscribe-0-textfooterglimmer-null-6b6odl~majnvnu4~2u-null-null&eid=6b6odl-majnvnu4-2u&loid=AQF_m2GmbZnRdwAAAZa_bvjNtUJ2v2HnuODb6qU_KnWqIOQQMIf4ywOi6UPkae7_mwXaXx9RsoFZ_yBIbsCsKMj68A\n",
      "Help: https://www.linkedin.com/help/linkedin/answer/67?lang=en&lipi=urn%3Ali%3Apage%3Aemail_email_m2m_invite_single_01%3Bmg310yLtQeCTh1ac%2FetW1Q%3D%3D&midToken=AQGV55UYyLjfaw&midSig=0tZWhdVUzIhHM1&trk=eml-email_m2m_invite_single_01-help-0-textfooterglimmer&trkEmail=eml-email_m2m_invite_single_01-help-0-textfooterglimmer-null-6b6odl~majnvnu4~2u-null-null&eid=6b6odl-majnvnu4-2u&otpToken=MTEwZDFmZTUxYTJhY2FjMmI1MjQwNGVkNDIxOGVlYjI4N2NhZDQ0Mjk4YWU4NjYxNzBjNjA4NmQ0YTViNWFmMmYwZDNkZjg0MWFjN2JlZmU1YTkwZDBhMWFjNjExM2U1OTYxZDAwNDY1NGM2YTA1Zjc5M2IzYiwxLDE%3D\n",
      "\n",
      "© 2025 LinkedIn Corporation, 1zwnj000 West Maude Avenue, Sunnyvale, CA 94085.\n",
      "LinkedIn and the LinkedIn logo are registered trademarks of LinkedIn.\n"
     ]
    }
   ],
   "source": [
    "import email\n",
    "from email.header import decode_header\n",
    "\n",
    "# Assume you've already connected, logged in, and selected mailbox\n",
    "# And you've done: status, msg_data = imap.fetch(email_ids[-1], '(RFC822)')\n",
    "\n",
    "for response_part in msg_data:\n",
    "    if isinstance(response_part, tuple):\n",
    "        # Parse the raw email content\n",
    "        msg = email.message_from_bytes(response_part[1])\n",
    "        \n",
    "        # Decode the email subject (title)\n",
    "        subject, encoding = decode_header(msg[\"Subject\"])[0]\n",
    "        if isinstance(subject, bytes):\n",
    "            subject = subject.decode(encoding or 'utf-8', errors='ignore')\n",
    "        \n",
    "        print(\"Subject (Title):\", subject)\n",
    "\n",
    "        # Initialize body\n",
    "        body = None\n",
    "\n",
    "        # Extract the plain-text part of the email\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "\n",
    "                if content_type == \"text/plain\" and \"attachment\" not in content_disposition:\n",
    "                    charset = part.get_content_charset() or 'utf-8'\n",
    "                    body = part.get_payload(decode=True).decode(charset, errors='ignore')\n",
    "                    break  # Stop after finding first plain text part\n",
    "        else:\n",
    "            charset = msg.get_content_charset() or 'utf-8'\n",
    "            body = msg.get_payload(decode=True).decode(charset, errors='ignore')\n",
    "\n",
    "        print(\"IRRELEVANT\" if body else \"No plain text found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c7944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import imaplib\n",
    "import email\n",
    "from email.header import decode_header\n",
    "\n",
    "# Already fetched the message:\n",
    "# status, msg_data = imap.fetch(email_ids[-1], '(RFC822)')\n",
    "\n",
    "for response_part in msg_data:\n",
    "    if isinstance(response_part, tuple):\n",
    "        msg = email.message_from_bytes(response_part[1])\n",
    "        \n",
    "        # Decode subject\n",
    "        subject, encoding = decode_header(msg[\"Subject\"])[0]\n",
    "        if isinstance(subject, bytes):\n",
    "            subject = subject.decode(encoding or 'utf-8', errors='ignore')\n",
    "        \n",
    "        print(\"Subject (Title):\", subject)\n",
    "\n",
    "        body = None\n",
    "\n",
    "        # Parse message parts\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "\n",
    "                if content_type == \"text/plain\" and \"attachment\" not in content_disposition:\n",
    "                    charset = part.get_content_charset() or 'utf-8'\n",
    "                    body = part.get_payload(decode=True).decode(charset, errors='ignore')\n",
    "                    break\n",
    "                elif content_type == \"text/html\" and body is None:\n",
    "                    charset = part.get_content_charset() or 'utf-8'\n",
    "                    html = part.get_payload(decode=True).decode(charset, errors='ignore')\n",
    "                    soup = BeautifulSoup(html, \"html.parser\")\n",
    "                    body = soup.get_text(separator=\"\\n\")  # Get readable text\n",
    "        else:\n",
    "            content_type = msg.get_content_type()\n",
    "            charset = msg.get_content_charset() or 'utf-8'\n",
    "            payload = msg.get_payload(decode=True).decode(charset, errors='ignore')\n",
    "\n",
    "            if content_type == \"text/plain\":\n",
    "                body = payload\n",
    "            elif content_type == \"text/html\":\n",
    "                soup = BeautifulSoup(payload, \"html.parser\")\n",
    "                body = soup.get_text(separator=\"\\n\")\n",
    "\n",
    "        print(\"Content (Body):\", body.strip() if body else \"No readable content found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ce2d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BYE', [b'IMAP4rev1 Server logging out'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BYE\n",
    "imap.close()\n",
    "imap.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365b85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "# Initialize the Groq client with your API key (recommended to set GROQ_API_KEY in your environment)\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "# Create a chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"llama3-8b-8192\",  # Specify the model you want to use\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of low latency LLMs, in 2 lines\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "254ac81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-latency Large Language Models (LLMs) are crucial for applications that\n",
      "require near-instant response times, such as chatbots, voice assistants, and\n",
      "real-time language translation, as they enable fast and accurate text processing\n",
      "and generation. By reducing the time it takes to process and respond to user\n",
      "input, low-latency LLMs improve user experience, increase productivity, and\n",
      "enable new use cases that rely on rapid language processing.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "display_text = textwrap.fill(chat_completion.choices[0].message.content, width=80)\n",
    "print(display_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    improved_joke: str\n",
    "    final_joke: str\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def generate_joke(state: State):\n",
    "    \"\"\"First LLM call to generate initial joke\"\"\"\n",
    "\n",
    "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "\n",
    "def check_punchline(state: State):\n",
    "    \"\"\"Gate function to check if the joke has a punchline\"\"\"\n",
    "\n",
    "    # Simple check - does the joke contain \"?\" or \"!\"\n",
    "    if \"?\" in state[\"joke\"] or \"!\" in state[\"joke\"]:\n",
    "        return \"Fail\"\n",
    "    return \"Pass\"\n",
    "\n",
    "\n",
    "def improve_joke(state: State):\n",
    "    \"\"\"Second LLM call to improve the joke\"\"\"\n",
    "\n",
    "    msg = llm.invoke(f\"Make this joke funnier by adding wordplay: {state['joke']}\")\n",
    "    return {\"improved_joke\": msg.content}\n",
    "\n",
    "def check_improved_joke(state: State):\n",
    "    \"\"\"Gate function to check if the joke has a punchline\"\"\"\n",
    "\n",
    "    # Simple check - does the joke contain \"?\" or \"!\"\n",
    "    if state[\"improved_joke\"]:\n",
    "        return \"Pass\"\n",
    "    return \"Fail\"\n",
    "\n",
    "def polish_joke(state: State):\n",
    "    \"\"\"Third LLM call for final polish\"\"\"\n",
    "\n",
    "    msg = llm.invoke(f\"Add a surprising twist to this joke: {state['improved_joke']}\")\n",
    "    return {\"final_joke\": msg.content}\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "workflow.add_node(\"improve_joke\", improve_joke)\n",
    "workflow.add_node(\"polish_joke\", polish_joke)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "workflow.add_edge(START, \"generate_joke\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_joke\", check_punchline, {\"Fail\": \"improve_joke\", \"Pass\": END}\n",
    ")\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"improve_joke\", check_improved_joke, {\"Fail\": \"generate_joke\", \"Pass\": \"polish_joke\"}\n",
    ")\n",
    "\n",
    "# workflow.add_edge(\"improve_joke\", \"polish_joke\")\n",
    "\n",
    "workflow.add_edge(\"polish_joke\", END)\n",
    "\n",
    "# Compile\n",
    "chain = workflow.compile()\n",
    "\n",
    "# Show workflow\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bfd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke\n",
    "state = chain.invoke({\"topic\": \"cats\"})\n",
    "print(\"Initial joke:\")\n",
    "print(state[\"joke\"])\n",
    "print(\"\\n--- --- ---\\n\")\n",
    "if \"improved_joke\" in state:\n",
    "    print(\"Improved joke:\")\n",
    "    print(state[\"improved_joke\"])\n",
    "    print(\"\\n--- --- ---\\n\")\n",
    "\n",
    "    print(\"Final joke:\")\n",
    "    print(state[\"final_joke\"])\n",
    "else:\n",
    "    print(\"Joke failed quality gate - no punchline detected!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
